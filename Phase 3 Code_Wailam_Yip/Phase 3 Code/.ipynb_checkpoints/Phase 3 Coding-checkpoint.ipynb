{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "%matplotlib qt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from difflib import SequenceMatcher\n",
    "import heapq as hq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some temporary lists or function(if any)\n",
    "\n",
    "#Simple function to check similarity of two strings\n",
    "def similar_check(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making DataFrame\n",
    "set_income = pd.read_csv(\"data476953875242305103.csv\",encoding = 'ISO-8859-1')\n",
    "set_character =  pd.read_csv(\"data452811046617372058.csv\",encoding = 'ISO-8859-1')\n",
    "set_occupation = pd.read_csv(\"data148408612782513151.csv\",encoding = 'ISO-8859-1')\n",
    "set_income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area with high population(in red color)\n",
    "high_pop = set_character[' erp_p_tot_cnt'].nlargest(8)\n",
    "high_pop_reg = []\n",
    "for j in high_pop:\n",
    "    for index in range(len(set_character)):\n",
    "        if set_character[' erp_p_tot_cnt'][index] == j:\n",
    "            high_pop_reg.append(set_character[' sa3_name16'][index])\n",
    "\n",
    "red_region = {'Area': high_pop_reg, 'Population': high_pop}\n",
    "red_region = pd.DataFrame(red_region)\n",
    "red_region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Attributes in set_Income\n",
    "df_income = set_income.iloc[:,1:3]  \n",
    "\n",
    "df_income['low_in'] = set_income[' negative_nil_income_tot']+set_income[' hi_1_149_tot'] + set_income[' hi_150_299_tot']+set_income[' hi_300_399_tot']+set_income[' hi_400_499_tot']\n",
    "df_income['mid_low_in'] = set_income[' hi_500_649_tot']+set_income[' hi_650_799_tot'] + set_income[' hi_800_999_tot']\n",
    "df_income['mid_in'] = set_income[' hi_1000_1249_tot']+set_income[' hi_1250_1499_tot'] + set_income[' hi_1500_1749_tot']+ set_income[' hi_1750_1999_tot']\n",
    "df_income['mid_high_in'] =set_income[' hi_2000_2499_tot'] + set_income[' hi_2500_2999_tot']+set_income[' hi_3000_3499_tot']\n",
    "df_income['high_in'] = set_income[' hi_3500_3999_tot'] + set_income[' hi_4000_more_tot']\n",
    "df_income['high_in_percent(%)'] = round(df_income['high_in']/df_income[' tot_tot']*100, 2)\n",
    "df_income['low_in_percent(%)'] = round(df_income['low_in']/df_income[' tot_tot']*100, 2)\n",
    "df_income[\"mid_in_percent(%)\"] = 100-df_income['high_in_percent(%)']-df_income['low_in_percent(%)']\n",
    "\n",
    "#Seeking top 10 regions with higest percentage of high income population\n",
    "top_10_high_in_hi = df_income['high_in_percent(%)'].nlargest(10)\n",
    "top_10_high_in_lw = []\n",
    "high_in_reg = []\n",
    "\n",
    "for j in top_10_high_in_hi:\n",
    "    for index in range(len(df_income)):\n",
    "        if df_income['high_in_percent(%)'][index] == j:\n",
    "            high_in_reg.append(df_income[' sa3_name16'][index])\n",
    "            top_10_high_in_lw.append(df_income['low_in_percent(%)'][index])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the top 10 highest percentage high income destrict\n",
    "top_10_high_in_hi.index = high_in_reg\n",
    "plot_dict = {\"High income %\":top_10_high_in_hi, \"Low income %\":top_10_high_in_lw}\n",
    "plot_dict = pd.DataFrame(plot_dict)\n",
    "plot_dict.plot.bar(width = 0.7, color=['g', 'y'], grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making CSV, so i can import it to Aurin for map visualisation\n",
    "df_income[' sa3_code16'] = set_income[' sa3_code16']\n",
    "df_income.to_csv(\"df_income.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Attributes in set_character\n",
    "#Wrong example of picking the raw data\n",
    "\n",
    "df_characterx = set_character.iloc[:,0:2]\n",
    "df_characterx[' sa3_name16'] = df_income[' sa3_name16']\n",
    "df_characterx['Total_pop'] = set_character[' erp_p_tot_cnt']\n",
    "df_characterx['children(%)'] = set_character[' erp_p_0_14_yrs_%']\n",
    "df_characterx['young_adult(%)'] = set_character[' erp_p_15_24_yrs_%']\n",
    "df_characterx['adult(%)']=set_character[' erp_p_25_34_yrs_%']+set_character[' erp_p_35_44_yrs_%']\n",
    "df_characterx['old_adult(%)'] =set_character[' erp_p_45_54_yrs_%']+set_character[' erp_p_55_64_yrs_%']\n",
    "df_characterx['senior(%)'] =set_character[' erp_p_65_74_yrs_%']+set_character[' erp_p_75_84_yrs_%']+set_character[' erp_p_85_yrs_&_over_%']\n",
    "\n",
    "empty = []\n",
    "per_tot = []\n",
    "for i in range(len(df_character)):\n",
    "    tot = df_characterx['children(%)'][i]+df_characterx['young_adult(%)'][i]+df_characterx['adult(%)'][i]+df_characterx['old_adult(%)'][i]+df_characterx['senior(%)'][i]\n",
    "    per_tot.append(tot)\n",
    "    if  (tot) == 100:\n",
    "        empty.append('T')\n",
    "    else:\n",
    "        empty.append('F')\n",
    "\n",
    "df_characterx[\"Total_per\"] = per_tot\n",
    "df_characterx['Validty'] = empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Attributes in set_character\n",
    "#Correct one\n",
    "\n",
    "df_character = set_character.iloc[:,0:2]\n",
    "df_character['Total_pop'] = set_character[' erp_p_tot_cnt']\n",
    "df_character['children'] = set_character[' erp_p_0_4_yrs_cnt']+set_character[' erp_p_5_9_yrs_cnt']+set_character[' erp_p_10_14_yrs_cnt']\n",
    "df_character['young_adult'] = set_character[' erp_p_15_19_yrs_cnt']+set_character[' erp_p_20_24_yrs_cnt']\n",
    "df_character['adult']=set_character[' erp_p_25_29_yrs_cnt']+set_character[' erp_p_30_34_yrs_cnt']+set_character[' erp_p_35_39_yrs_cnt']\n",
    "df_character['old_adult'] =set_character[' erp_p_40_44_yrs_cnt']+set_character[' erp_p_45_49_yrs_cnt']+set_character['erp_p_50_54_yrs_cnt']\n",
    "df_character['young_senior'] = set_character[' erp_p_55_59_yrs_cnt'] + set_character[' erp_p_60_64_yrs_cnt']\n",
    "df_character['senior'] =set_character[' erp_p_65_69_yrs_cnt']+set_character[' erp_p_70_74_yrs_cnt']+set_character[' erp_p_75_79_yrs_cnt']+set_character[' erp_p_80_84_yrs_cnt']+set_character[' erp_p_85_yrs_&_over_cnt']\n",
    "df_character[\"Au_citizen%\"] = set_character[\" citizenship_au_citizen_%\"]\n",
    "df_character[\"B_Euorpe\" ] = set_character[\" born_in_southern_&_eastern_eu_%\"]\n",
    "df_character[\"B_Africa\" ]= set_character[\" born_in_sub_saharan_africa_%\"]\n",
    "df_character[\"B_Central_Asia\" ]= set_character[\" born_in_southern_central_asia_%\"]\n",
    "df_character[\"B_America\" ]= set_character[\" born_in_americas_%\"]\n",
    "df_character[\"B_South_East_Asia\" ]= set_character[\" born_in_americas_%\"]\n",
    "df_character[\"B_Middle_East_North_Africa\" ]= set_character[\" born_in_north_africa_middle_east_%\"]\n",
    "df_character[\"B_Oceanic(exp AU)\"] = set_character[\" born_in_oceania_antarctica_(exc._aus)_%\"]\n",
    "df_character[\"B_North_East_Asia\"] = set_character[\" born_in_north_east_asia_%\"]\n",
    "df_character[\"Unknown_Nation\" ]= set_character[\" citizenship_not_stated_%\"]\n",
    "\n",
    "#Correct the sa3 code name, some regions are same however python cannot recognize the slight different\n",
    "for name in df_income[' sa3_name16']:\n",
    "    for index in range(len(df_character)):\n",
    "        similarity =  similar_check(name, df_character[' sa3_name16'][index])\n",
    "        if similarity >= 0.9:\n",
    "            df_character[' sa3_name16'][index] = name\n",
    "\n",
    "df_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AU Citizen count in top 10 high-income regions\n",
    "Ct_count = []\n",
    "\n",
    "for region in high_in_reg:\n",
    "    for index in range(len(df_income)):\n",
    "        if df_character[' sa3_name16'][index] == region:\n",
    "            Ct_count.append(df_character[\"Au_citizen%\"][index])\n",
    "\n",
    "#Calculate the mean value of AU citizen in the top 10 high-income regions\n",
    "Summ = 0\n",
    "for value in Ct_count:\n",
    "    Summ += value\n",
    "\n",
    "Ct_count_mean = round(Summ/len(Ct_count),2) \n",
    "Ct_count_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Composition of Nationality in Bayside\n",
    "#1 AU citizen percentage\n",
    "Citiz = [85.4, 14.6]\n",
    "Citiz_label = [\"AU Citizen\",\"Other Nationalities\"]\n",
    "plt.pie(Citiz, labels=Citiz_label, shadow=True, autopct='%1.1f%%', startangle=90)\n",
    "plt.title(\"Citizenship in Bayside\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Composition of other Nationality\n",
    "Other_Nat = df_character.iloc[27,10:].values\n",
    "Nat_Lab = ['B_Euorpe','B_Africa','B_Central_Asia','B_America','B_South_East_Asia','B_Middle_East_North_Africa','B_Oceanic(exp AU)','B_North_East_Asia','Unknown_Nation']\n",
    "plt.pie(Other_Nat,labels=Nat_Lab, shadow=True, autopct='%1.1f%%', startangle=90)\n",
    "plt.title(\"Citizenship in Bayside\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize the population \n",
    "unnorm_popu = df_character['Total_pop']\n",
    "norm_popu = []\n",
    "max1 = max(unnorm_popu)\n",
    "min1 = min(unnorm_popu)\n",
    "for value in unnorm_popu:\n",
    "    newvalue = round((value - min1)/(max1-min1),2)\n",
    "    norm_popu.append(newvalue)\n",
    "    \n",
    "df_character[\"norm_pop\"] = norm_popu\n",
    "\n",
    "#Find correlation between population and high income percentage\n",
    "\n",
    "high_in_percent = df_income['high_in_percent(%)']\n",
    "plt.scatter(x=norm_popu, y=high_in_percent)\n",
    "plt.xlabel('Normalized Population in 66 Regions')\n",
    "plt.ylabel(\"High income Percentage with respect to total population in that region\")\n",
    "plt.title(\"Correlation between population and Income(High)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find correlation between population and low income percentage\n",
    "\n",
    "low_in_percent = df_income['low_in_percent(%)']\n",
    "plt.scatter(x=norm_popu, y=low_in_percent, color=['g'])\n",
    "plt.xlabel('Normalized Population in 66 Regions')\n",
    "plt.ylabel(\"Low income Percentage with respect to total population in that region\")\n",
    "plt.title(\"Correlation between population and Income(Low)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging Attributes in occupation in Bayside\n",
    "df_occupation = set_occupation.iloc[27, :]\n",
    "\n",
    "#del some useless attributes\n",
    "del df_occupation[' sa3_code16']\n",
    "del df_occupation[' sa3_name16']\n",
    "for att in list(set_occupation):\n",
    "    if 'to' in att:\n",
    "        del df_occupation[att]\n",
    "\n",
    "#Find top 5 largest value of occupation in Bayside\n",
    "occup_val = []\n",
    "for index in df_occupation:\n",
    "    occup_val.append(index)    \n",
    "val = hq.nlargest(5, occup_val)\n",
    "\n",
    "#And then find the name of the occupation\n",
    "result_att = []\n",
    "\n",
    "for value in val:\n",
    "    for att in list(set_occupation):\n",
    "        for index in range(len(set_occupation)):\n",
    "            if set_occupation[' sa3_name16'][index] == 'Bayside':\n",
    "                if set_occupation[att][index] == value:\n",
    "                    result_att.append((att, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Table graph of their occupations in the top 5 high income regions\n",
    "Table_chart_data = []\n",
    "temp = []\n",
    "for att in result_att[:5]:\n",
    "    for region in high_in_reg[:5]:\n",
    "        for index in range(len(set_occupation)):\n",
    "            if set_occupation[' sa3_name16'][index] == region:\n",
    "                temp.append(set_occupation[att[0]][index])\n",
    "    Table_chart_data.append(temp)\n",
    "    temp = []\n",
    "\n",
    "columns = (\"psc_tech_pfn\", \"hlth_sass_pfn\", \"edtr_pfn\", \"retr_sal\", \"finin_pfn\")\n",
    "rows = ['Stonnington - West','Manningham - East','Boroondara','Stonnington - East', 'Bayside']\n",
    "rows.reverse()\n",
    "\n",
    "#Make transposes of a 2D list\n",
    "Table_chart_data = list(map(list, zip(*Table_chart_data)))\n",
    "\n",
    "#Get some pastel shades for the colors\n",
    "colors = plt.cm.BuPu(np.linspace(0.3, 0.7, len(rows)))\n",
    "n_rows = len(Table_chart_data)\n",
    "\n",
    "index = np.arange(len(columns))\n",
    "bar_width = 0.5\n",
    "\n",
    "# Initialize the vertical-offset for the stacked bar chart.\n",
    "y_offset = np.zeros(len(columns))\n",
    "\n",
    "# Plot bars and create text labels for the table\n",
    "cell_text = []\n",
    "for row in range(n_rows):\n",
    "    plt.bar(index, Table_chart_data[row], bar_width, bottom=y_offset, color=colors[row])\n",
    "    y_offset = Table_chart_data[row]\n",
    "    cell_text.append([(x) for x in y_offset])\n",
    "# Reverse colors and text labels to display the last value at the top.\n",
    "colors = colors[::-1]\n",
    "cell_text.reverse()\n",
    "\n",
    "# Add a table at the bottom of the axes\n",
    "the_table = plt.table(cellText=cell_text,\n",
    "                      rowLabels=rows,\n",
    "                      rowColours=colors,\n",
    "                      colLabels=columns,\n",
    "                      loc='bottom')\n",
    "\n",
    "# Adjust layout to make room for the table:\n",
    "plt.subplots_adjust(left=0.3, bottom=0.3)\n",
    "plt.title('Top 5 Occupation in Bayside with respect to other top 5 Regions ')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayside\n",
    "#set_character['  erp_p_tot_cnt']\n",
    "df_bayside = pd.Series([])\n",
    "df_bayside = df_income.iloc[22,:] \n",
    "df_bayside = pd.DataFrame(df_bayside)\n",
    "\n",
    "#This series is for plotting pie charta\n",
    "df_bayside_pop = df_character.iloc[27,:]\n",
    "Attr = ['children(0-14)','young_adult(15-24)','adult(25-39)','old_adult(40-54)','young_senior(55-64)','senior(65 or above)']\n",
    "col = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\"]\n",
    "\n",
    "pie_bayside = []\n",
    "for index,value in enumerate(df_bayside_pop):\n",
    "    if index >= 3 and index <= 8:\n",
    "        pie_bayside.append(value)\n",
    "        \n",
    "plt.pie(pie_bayside, labels=Attr,  colors=col, shadow=True, autopct='%1.1f%%', startangle=90)\n",
    "plt.title(\"Age Distribution in Bayside\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
